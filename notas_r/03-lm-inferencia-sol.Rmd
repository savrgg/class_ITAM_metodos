---
title: "Ejemplo clase"
output:
  pdf_document: default
  html_notebook: default
---

# Sección 1
## Introducción

Este ejemplo es la versión en R del ejercicio visto en clase. Primero se guardan los datos en un data.frame llamado d: 

```{r}
library(tidyverse)
library(tidymodels)

x <- c(-2, -1, 0, 1, 2)
y <- c(0, 0, 1, 1, 3)

d <- data.frame(x = x, y =y)
d
```

Se realiza un exploratorio para observar los datos:

```{r}
d %>%
  ggplot(aes(x = x, y = y))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_minimal()+
  labs(title = "Ejemplo regressión lineal")
```

Se ajusta la regresión lineal:

```{r}
lm_fit <- 
  linear_reg() %>% 
  fit(y ~ x, data = d)

tidy(lm_fit)  
data.frame(glance(lm_fit))
```

### Inciso 1: Calcule $\bar{X}$, $\bar{Y}$, ${S^2_X}$, ${S^2_Y}$, ${S_{xy}}$
```{r}
# 1) 
xbar = mean(d$x)
ybar = mean(d$y)
sx2 = var(d$x)
sy2 = var(d$y)
sxy = cov(d$x, d$y)
```

### Inciso 2: Calcule $\hat{\beta}_0$ y $\hat{\beta}_1$:
```{r}
B1 <- sxy/sx2
B0 <- ybar - B1*xbar
```

### Inciso 3: Calcule TSS, ESS, RSS, $R^2$ y $adjR^2$
```{r}
yhat <- predict(lm_fit, new_data = d %>% select(x))
TSS <- sum((d$y-ybar)**2)
ESS <- sum((yhat-ybar)**2)
RSS <- sum((d$y-yhat)**2)
R2 <- ESS/TSS
adjR2 <- 1- ((1-R2)*(5-1))/(5-1-1)
```

### Inciso 4: Calcule $\hat{\sigma^2}$, $\hat{V(\hat{\beta_0})}$, $\hat{V(\hat{\beta_1})}$
```{r}
sigma2hat <- RSS/(5-2)
sigmahat <- sqrt(sigma2hat)

sigma2_B0 <- sigma2hat*(1/5 + 0/(sx2*(5-1)))
sigma2_B1 <- sigma2hat/(sx2*(5-1))

sigma_B0 <- sqrt(sigma2_B0)
sigma_B1 <- sqrt(sigma2_B1)
```

### Inciso 5: Pruebas de hipótesis coeficientes:
```{r}
T_B1 = (B1-0)/sqrt(sigma2_B1)
T_B0 = (B0-0)/sqrt(sigma2_B0)

2*(1-pt(T_B1, df = 5-2))
2*(1-pt(T_B0, df = 5-2))
```

### Inciso 6: Pruebas de hipótesis correlación:
```{r}
rxy = sxy/(sqrt(sx2)*sqrt(sy2))
T_corr = (rxy*sqrt(5-2))/sqrt(1-rxy**2)
2*(1-pt(T_corr, df = 5-2))
```

### Inciso 7: Comprobación de propiedades
```{r}
# recta pasa por la media
d %>%
  ggplot(aes(x = x, y = y))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_minimal()+
  geom_point(x=xbar, y = ybar, color = "red")+
  labs(title = "Ejemplo regressión lineal")
# suma de residuos es 0
sum(d$y-yhat)
# residuos no están correlacionados con x
r_rx = cor(d$x, d$y-yhat)
# residuos no están correlacionados con yhat
r_ryhat = cor(yhat, d$y-yhat)

```

### Inciso 8: Prueba F
```{r}
Fest = (ESS/1)/(RSS/3)
Fest
pf(Fest, df1 = 1, df2 = 3, lower.tail = F)
```



### Inciso 9: Predicción a la media
```{r}
mean_pred <- predict(lm_fit, new_data = data.frame(x = c(0,3)))
int_pred <- predict(lm_fit, new_data = data.frame(x = c(0,3)), 
                    type = "conf_int", level = .95)
plot_data <- 
  data.frame(x = c(0,3)) %>% 
  bind_cols(mean_pred) %>% 
  bind_cols(int_pred) %>% 
  mutate(
    error_pred = sigmahat*sqrt((1/5)+(((x-xbar)**2)/(sx2*(5-1)))),
    errorind_pred = sigmahat*sqrt(1+(1/5)+(((x-xbar)**2)/(sx2*(5-1)))),
    pred_lower_formula = .pred-qt(.975, df = 3)*error_pred,
    pred_upper_formula = .pred+qt(.975, df = 3)*error_pred,
    pred_lowerind_formula = .pred-qt(.975, df = 3)*errorind_pred,
    pred_upperind_formula = .pred+qt(.975, df = 3)*errorind_pred)

plot_data
```
### Inciso 9: Predicción individual
```{r}

```

# Sección 2) Ejercicio
## Introducción

El problema presentado en este ejercicio es determinar si existe una relación lineal entre la edad de un niño y su altura. Se tiene la intuición que a mayor edad, más alto es. A continuación se presentan los datos de edad (meses) y altura (cm) en una muestra de 12 niños

```{r}
data <- read_csv("https://raw.githubusercontent.com/savrgg/class_ITAM_metodos/main/notas_r/ageandheight.csv")
data
```

####  1. Determine por medio de una gráfica si es razonable pensar en que existe una relación lineal entre las variables (variable independiente: edad)
```{r}
data %>%
  ggplot(aes(x = age, y = height))+
  geom_point()+
  geom_smooth(method = "lm", se = F)+
  theme_minimal()+
  labs(x = "Edad (meses)",
       y = "Altura (cm)",
       title = "Relación lineal entre altura y edad de niños",
       subtitle = "Muestra de la altura y edad de 12 niños")
```

Al comparar gráficamente los datos, podemos observar que los datos si se ajustan por medio de una línea. 

#### 2. Determine con una Prueba de Hipótesis si existe una relación lineal entre las variables.

Para determinar si existe una relación lineal, se construye una Prueba de Hipótesis del coeficiente de correlación. Recordando, el coeficiente de correlación mide solamente la asociación lineal, mas no la pendiente de la linea

Sea $H_0: \rho = 0$ y $H_1: \rho \neq 0$, entonces: 

```{r}
n = nrow(data)
ybar = mean(data$height)
xbar = mean(data$age)
sxy = cov(data$age, data$height)
sx2 = var(data$age)
sy2 = var(data$height)
rxy = sxy/(sqrt(sx2)*sqrt(sy2))
T_corr = (rxy*sqrt(n-2))/sqrt(1-rxy**2)
T_corr
2*(1-pt(T_corr, df = n-2))
```

El $valor-p$ es cercano a 0, entonces rechazamos $H_0: \rho = 0$, por lo que rechazamos que la correlación sea cero.

#### 3. Utilicé tidymodels (lm) para realizar la regresión lineal, analice los resultados obtenidos
```{r}
lm_fit <- 
  linear_reg() %>% 
  fit(height ~ age, data = data)

tidy(lm_fit)  
data.frame(glance(lm_fit))
```


#### 4. Determine analíticamente los coeficientes $\hat{\beta}_0$ y $\hat{\beta}_1$
```{r}
B1 <- sxy/sx2
B0 <- ybar - B1*xbar
B1
B0
```
### 5. Calcule analíticamente TSS, ESS, RSS, $R^2$ y $adjR^2$

```{r}
yhat <- predict(lm_fit, new_data = data %>% select(age))
TSS <- sum((data$height-ybar)**2)
ESS <- sum((yhat-ybar)**2)
RSS <- sum((data$height-yhat)**2)
R2 <- ESS/TSS
adjR2 <- 1- ((1-R2)*(n-1))/(n-1-1)
```

### 6. Calcule analíticametne $\hat{\sigma^2}$, $\hat{V(\hat{\beta_0})}$, $\hat{V(\hat{\beta_1})}$
```{r}
sigma2hat <- RSS/(n-2)
sigmahat <- sqrt(sigma2hat)

sigma2_B0 <- sigma2hat*(1/n + (xbar*xbar)/(sx2*(n-1)))
sigma2_B1 <- sigma2hat/(sx2*(n-1))

sigma_B0 <- sqrt(sigma2_B0)
sigma_B1 <- sqrt(sigma2_B1)

sigma_B0
sigma_B1
```

### 7. Determine si el valor de los coeficientes es significativo (realice una prueba para cada uno)
```{r}
T_B1 = (B1-0)/sqrt(sigma2_B1)
T_B0 = (B0-0)/sqrt(sigma2_B0)

T_B1
T_B0

2*(1-pt(T_B1, df = n-2))
2*(1-pt(T_B0, df = n-2))
```

El valor-p de ambas pruebas es cercano a 0, por lo que podemos rechazar que $H_0: \beta_1 = 0$ y $H_0: \beta_0 = 0$

### 8. Comprueba que:
a) Suma de residuales es igual a 0
```{r}
sum(data$height-yhat)
```

b) Residuos no están correlacionados a X
```{r}
cor(data$age, data$height-yhat)
```

c) Residuos no están correlacionados a $\hat{Y}$
```{r}
cor(yhat, data$height-yhat)
```

### 9. Determine si el de $R^2$ es significativo
```{r}
Fest = (ESS/1)/(RSS/(n-2))
Fest
pf(Fest, df1 = 1, df2 = (n-2), lower.tail = F)
```


El $valor-p$ es cercano a 0,por lo que podemos rechazar $H_0: \rho^2 = 0$ vs $H_1: \rho^2 > 0$.


### Calcula la predicción a la media para una edad 25 años. Calcule el IC al 95%.

```{r}
yhat_25 <- B0+B1*25
quantil_t = qt(.975, df = n-2)
lim_inf = yhat_25 - quantil_t*sigmahat*sqrt(1/n + ((25-xbar)^2)/(sx2*(n-1)))
lim_sup = yhat_25 + quantil_t*sigmahat*sqrt(1/n + ((25-xbar)^2)/(sx2*(n-1)))
```
IC para prediccion media de edad 25: (80.62294, 80.98196)


### Calcula la predicción individual para un valor de 30 años. Calcule el IC al 95

```{r}
yhat_30 <- B0+B1*30
quantil_t = qt(.975, df = n-2)
lim_inf = yhat_30 - quantil_t*sigmahat*sqrt(1/n + ((30-xbar)^2)/(sx2*(n-1)))
lim_sup = yhat_30 + quantil_t*sigmahat*sqrt(1/n + ((30-xbar)^2)/(sx2*(n-1)))
```
IC para prediccion individual de edad 30: (83.62626, 84.32828)




